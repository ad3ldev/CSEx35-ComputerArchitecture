{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AbdelRahman Adel AbdelFattah\n",
        "## 17012296\n",
        "### Initializing the code"
      ],
      "metadata": {
        "id": "QYaCuwfbUqJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading PyCUDA"
      ],
      "metadata": {
        "id": "4LkUEteCVGp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycuda"
      ],
      "metadata": {
        "id": "LEahy6GgUpT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0362dc4c-3057-491c-a467-b6411b83049c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp39-cp39-linux_x86_64.whl size=661964 sha256=16e98700c4eab4a04226fd1351b9ef0fc9ebe9314b9811a790e9b6b772e71399\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/09/27/74d8e31ed19c530166e0d263aabe1ea57465e255615bda8fc0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69866 sha256=2e46ea6a51f53dcb0e8b16fec7016321ba543857fcd1a8e3b7c2aa5ddb201330\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/8c/332750bd78e80cdef14a96eb5b539adf0dcda50a97bbdfcbd8\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pycuda import compiler, gpuarray, tools\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import time"
      ],
      "metadata": {
        "id": "muMOZnwXuB3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Kernel code that will use the GPU directly.\n",
        "GPU functions."
      ],
      "metadata": {
        "id": "qf_FiTgPVLTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_code = \"\"\"\n",
        "__global__ void multi_gpu(int matrixsize,float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "    int ty = blockDim.y*blockIdx.y + threadIdx.y;\n",
        "\n",
        "    if((ty <matrixsize) && (tx < matrixsize)){\n",
        "      float Pvalue = 0;\n",
        "      for(int k=0; k<matrixsize;++k){\n",
        "        float Aelement = a[ty*matrixsize +k];\n",
        "        float Belement = b[k*matrixsize +tx];\n",
        "        Pvalue += Aelement * Belement;\n",
        "      }\n",
        "      c[ty * matrixsize + tx] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void add_gpu(int matrixsize,float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "    int ty = blockDim.y*blockIdx.y + threadIdx.y;\n",
        "\n",
        "    if((ty <matrixsize) && (tx < matrixsize)){\n",
        "      float Aelement = a[ty * matrixsize + tx];\n",
        "      float Belement = b[ty * matrixsize + tx];\n",
        "      c[ty * matrixsize + tx] = Aelement + Belement;\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "v1l-YIDmMypB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for CPU"
      ],
      "metadata": {
        "id": "WThH3nmtVRVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cpu(matrix_a, matrix_b):\n",
        "  result = np.zeros((matrix_a.shape[0], matrix_a.shape[1]))\n",
        "  for i in range(matrix_a.shape[0]):\n",
        "    for j in range(matrix_a.shape[1]):\n",
        "      result[i][j] = matrix_a[i][j] + matrix_b[i][j]\n",
        "  return result"
      ],
      "metadata": {
        "id": "lvpuCHS5uE3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_cpu(matrix_a, matrix_b):\n",
        "  result = np.zeros((matrix_a.shape[0], matrix_a.shape[1]))\n",
        "  for i in range(matrix_a.shape[0]):\n",
        "    for j in range(matrix_b.shape[1]):\n",
        "      for k in range(matrix_b.shape[0]):\n",
        "        result[i][j] += matrix_a[i][k] * matrix_b[k][j];\n",
        "  return result"
      ],
      "metadata": {
        "id": "kwwSz1HoxW7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "multi_gpu = mod.get_function(\"multi_gpu\")\n",
        "add_gpu = mod.get_function(\"add_gpu\")\n",
        "\n",
        "BLOCK_SIZE = 32\n",
        "MAX_NUM = 1024\n",
        "\n",
        "MATRIX_SIZE = 3\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "ENnayGw2NJzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating different sizes and calculating the time."
      ],
      "metadata": {
        "id": "H56CziwDVetu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix size = 3"
      ],
      "metadata": {
        "id": "fvwnDi73VpMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 3\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "RvFtm3KcWkTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "fnkp-GFjWnp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72ce2c3-c2b7-4e64-ed13-928daedb4a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0037767887115478516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "ezLi2FcOWrPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191166ef-92af-47c8-8688-71ca94f058b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0012199878692626953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix size = 10"
      ],
      "metadata": {
        "id": "DgX3LPBeV4m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 10\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "1_KqyHMBXqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "4XYeLLElXrMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3bd0e4-e38e-4e1c-e116-e6215da0a707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0002346038818359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "gK_wLnwzXuLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f31218c-fa81-48af-996f-cd54c0e53a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0003705024719238281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix size = 100"
      ],
      "metadata": {
        "id": "H2hu0-NSWL5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 100\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "PuZr_kzvX1Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "1FJpuoiyX2V2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51788596-072a-41fd-d533-1c0d372e434c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.005835771560668945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "ce0qVV0zX4SB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16b3ffb-e525-4276-af04-bb3a4e2b2975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0005102157592773438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Size = 1,000"
      ],
      "metadata": {
        "id": "dfex2O0qWO4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 1_000\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "__cWquV1X8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e16ec9-ce18-452d-d595-e4d34a889da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "evYgTqqUX-Jz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b56b06c-4171-40fa-e9a7-97e14888f30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.06137251853942871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "7bo9Oa7eYBQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eeb3fb9-1ece-4c99-d01b-90db042456b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0005323886871337891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Size = 5,000"
      ],
      "metadata": {
        "id": "YqVFxmHRWZMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 5_000\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "jqko38-2YEEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c7c3d0-5040-45c0-92de-45d43bec6e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "XJJvaoaGYFOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75db67db-5269-40e8-802c-8f74bce0b6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 3.5989608764648438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "7TaWQk5lYG0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34994d84-732a-4373-9bec-a7573a116843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0004749298095703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Size = 10,000"
      ],
      "metadata": {
        "id": "fskc5qrWWRUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 10_000\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "PZPdQXh4YI_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaa6d35-a615-4b63-cbd9-777d871bbd37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "2lN8-4QDYMTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b9879d-67c3-48ef-ec10-9ae3781f979f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 30.343129634857178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "07w3San_YNAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e36dcd-5a6c-4cf9-8777-f7b227d02f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.000492095947265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Size = 15,000"
      ],
      "metadata": {
        "id": "vqCkU7IsWWSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX_SIZE = 15_000\n",
        "\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "matrixsize=MATRIX_SIZE\n",
        "\n",
        "a_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "b_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "c_cpu = np.random.randint(MAX_NUM,size=(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.to_gpu(c_cpu)"
      ],
      "metadata": {
        "id": "9c2pldxDYP24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76693f36-9adb-4ca3-d43d-d6622b6d995f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "start = time.time()\n",
        "temp1_cpu = a_cpu + b_cpu\n",
        "temp2_cpu = np.dot(a_cpu, temp1_cpu)\n",
        "temp3_cpu = temp2_cpu + c_cpu\n",
        "end = time.time()\n",
        "\n",
        "a_cpu = temp3_cpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "0dgn-C5sYTAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c50251f-3a25-4bac-b4d7-f20ec45b49ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 91.37070488929749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "temp1_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp2_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "temp3_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "start = time.time()\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, b_gpu,\n",
        "    temp1_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "multi_gpu(np.uint32(matrixsize),\n",
        "    a_gpu, temp1_gpu,\n",
        "    temp2_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "add_gpu(np.uint32(matrixsize),\n",
        "    temp2_gpu, c_gpu,\n",
        "    temp3_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1))\n",
        "end = time.time()\n",
        "\n",
        "a_gpu = temp3_gpu\n",
        "print(f'Finished in: {end-start}')"
      ],
      "metadata": {
        "id": "uqUbhyA0YUrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d556ce7-0e9b-44df-ff29-1dd6bf8ca2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in: 0.0005667209625244141\n"
          ]
        }
      ]
    }
  ]
}